{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supresses NonCritical Warnings of Tensorflow\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code imports the TensorFlow library and then enables memory growth for GPU devices, if any are available.\n",
    "# Important for some runtime errors during model execution\n",
    "import tensorflow as tf\n",
    "\n",
    "# Enable memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## !pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:38.775015Z",
     "iopub.status.busy": "2023-11-23T03:50:38.774606Z",
     "iopub.status.idle": "2023-11-23T03:50:46.222910Z",
     "shell.execute_reply": "2023-11-23T03:50:46.222132Z",
     "shell.execute_reply.started": "2023-11-23T03:50:38.774983Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your own dataset for text classification. It should contain at least 1000 words in total and at least two categories with at least 100 examples per category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created the dataset by scraping the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:46.231848Z",
     "iopub.status.busy": "2023-11-23T03:50:46.231578Z",
     "iopub.status.idle": "2023-11-23T03:50:46.250060Z",
     "shell.execute_reply": "2023-11-23T03:50:46.249146Z",
     "shell.execute_reply.started": "2023-11-23T03:50:46.231824Z"
    }
   },
   "outputs": [],
   "source": [
    "headers = ({'User Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36', 'Accept-Language':'en-US, en;q=0.5'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:46.252230Z",
     "iopub.status.busy": "2023-11-23T03:50:46.251960Z",
     "iopub.status.idle": "2023-11-23T03:50:46.259584Z",
     "shell.execute_reply": "2023-11-23T03:50:46.258771Z",
     "shell.execute_reply.started": "2023-11-23T03:50:46.252207Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://newsapi.org/v2/top-headlines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:46.260774Z",
     "iopub.status.busy": "2023-11-23T03:50:46.260544Z",
     "iopub.status.idle": "2023-11-23T03:50:46.581668Z",
     "shell.execute_reply": "2023-11-23T03:50:46.580960Z",
     "shell.execute_reply.started": "2023-11-23T03:50:46.260753Z"
    }
   },
   "outputs": [],
   "source": [
    "webpage = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:46.583408Z",
     "iopub.status.busy": "2023-11-23T03:50:46.583155Z",
     "iopub.status.idle": "2023-11-23T03:50:46.589843Z",
     "shell.execute_reply": "2023-11-23T03:50:46.588967Z",
     "shell.execute_reply.started": "2023-11-23T03:50:46.583386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [401]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webpage # should get response [200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:46.591238Z",
     "iopub.status.busy": "2023-11-23T03:50:46.590945Z",
     "iopub.status.idle": "2023-11-23T03:50:46.598855Z",
     "shell.execute_reply": "2023-11-23T03:50:46.598104Z",
     "shell.execute_reply.started": "2023-11-23T03:50:46.591215Z"
    }
   },
   "outputs": [],
   "source": [
    "# set the request parameters\n",
    "params = {\n",
    "    'category': 'technology',\n",
    "    'language': 'en',\n",
    "    'pageSize': 100,\n",
    "    'apiKey': 'e30743332dd1426eb170927023ba09d7'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:46.600021Z",
     "iopub.status.busy": "2023-11-23T03:50:46.599749Z",
     "iopub.status.idle": "2023-11-23T03:50:47.314701Z",
     "shell.execute_reply": "2023-11-23T03:50:47.313810Z",
     "shell.execute_reply.started": "2023-11-23T03:50:46.599992Z"
    }
   },
   "outputs": [],
   "source": [
    "response = requests.get(url, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:47.316822Z",
     "iopub.status.busy": "2023-11-23T03:50:47.316563Z",
     "iopub.status.idle": "2023-11-23T03:50:47.320709Z",
     "shell.execute_reply": "2023-11-23T03:50:47.319799Z",
     "shell.execute_reply.started": "2023-11-23T03:50:47.316797Z"
    }
   },
   "outputs": [],
   "source": [
    "#response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:47.326180Z",
     "iopub.status.busy": "2023-11-23T03:50:47.325779Z",
     "iopub.status.idle": "2023-11-23T03:50:47.332828Z",
     "shell.execute_reply": "2023-11-23T03:50:47.331968Z",
     "shell.execute_reply.started": "2023-11-23T03:50:47.326148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:47.334206Z",
     "iopub.status.busy": "2023-11-23T03:50:47.333942Z",
     "iopub.status.idle": "2023-11-23T03:50:47.342553Z",
     "shell.execute_reply": "2023-11-23T03:50:47.341674Z",
     "shell.execute_reply.started": "2023-11-23T03:50:47.334183Z"
    }
   },
   "outputs": [],
   "source": [
    "articles = response.json()['articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:47.344512Z",
     "iopub.status.busy": "2023-11-23T03:50:47.343637Z",
     "iopub.status.idle": "2023-11-23T03:50:47.352028Z",
     "shell.execute_reply": "2023-11-23T03:50:47.351173Z",
     "shell.execute_reply.started": "2023-11-23T03:50:47.344486Z"
    }
   },
   "outputs": [],
   "source": [
    "Tech_titles = [article['title'].split(' - ')[0].split(' | ')[0] for article in articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:47.353403Z",
     "iopub.status.busy": "2023-11-23T03:50:47.353076Z",
     "iopub.status.idle": "2023-11-23T03:50:47.362847Z",
     "shell.execute_reply": "2023-11-23T03:50:47.361977Z",
     "shell.execute_reply.started": "2023-11-23T03:50:47.353369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beeper Mini's iMessage integration is on the fritz\n",
      "PUBG Mobile guide to avoid dying (December 2023)\n",
      "Apple's iPhone and Watch Product Design Chief to Leave in Shake-Up\n",
      "Den of Wolves\n",
      "Minecraft – Jurassic World DLC – Nintendo Switch\n",
      "Round 2: We test the new Gemini-powered Bard against ChatGPT\n",
      "Apple Wallet ticket sharing is becoming more like NameDrop\n",
      "GTA Vice City map vs GTA 6 map: Everything known so far from leaks and trailer\n",
      "A brain without a body can now be kept alive for hours, thanks to new tech\n",
      "Hideo Kojima Teams With Jordan Peele for Upcoming Horror Game ‘OD,’ Announces His ‘Death Stranding’ Docu Will Stream on Disney+\n",
      "Google’s AI-assisted NotebookLM note-taking app is now open to users in the US\n",
      "Google faces controversy over edited Gemini AI demo video\n",
      "Chimney for modern homes: Here are top 10 options to consider before buying one\n",
      "The Game Awards 2023: All The Biggest Announcements\n",
      "Battlegrounds Mobile India (BGMI): Mid-range guide (December 2023)\n",
      "This brand made an $1,100 edible gold iPhone 15 Pro Max chocolate bar\n",
      "In 1990, You Could Get A Chevy 1500 With 405 Lb-Ft Of Torque From A Big Block V8: Holy Grails\n",
      "Hogwarts Legacy – Live the Unwritten Trailer – Nintendo Switch\n",
      "Why AI Chess Bots Are Virtually Unbeatable (ft. GothamChess)\n",
      "Pasta dinner in just 1 minute? This viral hack shows how — but there's a catch\n",
      "Starfield Testers Had To Unionize To Get A Copy Of The Game\n",
      "The Day Before's overwhelmingly negative Steam reviews seem deserved\n",
      "You Can Use Meta's New AI Image Generator for Free\n",
      "For some reason Yamaha is launching a 5-disk CD changer in 2023\n",
      "'Jurassic Park: Survival' trailer teases what happened to raptor in freezer\n",
      "God of War Ragnarok: Valhalla Set After Main Game as Kratos Faces His Past in a Personal Story\n",
      "OnePlus 12 confirmed to launch globally on January 23\n",
      "Flipkart announces 'Big Year End Sale', starts from this Saturday\n",
      "WhatsApp rolls out `View Once` voice message feature\n",
      "Best Buy's New Weekend Sale Has Record Low Prices on MacBook Pro and MacBook Air\n",
      "Drama, ghosting and tales of misery on NYC's 'cutthroat' dating scene: 'We’re all out for ourselves'\n",
      "Tech this week: NoiseFit Endeavour to Google’s Gemini, check top tech launches\n",
      "This Week In Security: LogoFail, National DNS Poison, And DNA\n",
      "This Dealer Is Trying To Sell A 1995 Honda Accord For More Than The Original MSRP\n",
      "Huge surge in malicious phishing emails attributed to AI tools like ChatGPT\n",
      "Sony PlayStation VR2 Price In India New Headset With Horizon Call of the Mountain Bundle Launched; Know Specs, Availability\n",
      "The Finals’ Playercount Is Exploding After Surprise Game Awards Release\n",
      "Sonos Holiday Sale Offers Perfect Holiday Gifts for the Audiophile in Your Life\n",
      "Alan Wake 2: 'The Final Draft' Update Includes New Game Plus And New Ending, Out Next Week\n",
      "Tears of the Kingdom Devs Leave Door Open for Playable Zelda in Potential Future Release\n",
      "Best games of 2023: ‘Starfield,’ ‘Baldur’s Gate 3’ and more\n",
      "How to get LEGO Fortnite True Explorers Quest Pack for free\n",
      "Baldur's Gate 3 Is Now Available On Xbox Series X/S\n",
      "CMF Buds Pro by Nothing: Quick Review\n",
      "Google REMOVES 17 apps with over 1 crore downloads for SNOOPING on users, say reports\n",
      "Vacuum cleaner for car: 10 best options to consider before purchase\n",
      "iPhone SE 4 said to get a major upgrade in battery and design\n",
      "The Big Vision Behind These iOS, WatchOS Updates\n",
      "Best premium tablets of 2023: Samsung Galaxy Tab S9 Ultra to Google Pixel tablet, check top 5 here\n",
      "Yes, Apple just made an AI announcement of its own. No, it's not a Gemini competitor\n",
      "Google adding dedicated 'Weather' shortcut to app grid on Pixel\n",
      "Google rolls out migration tool ahead of its Podcasts shutdown in April 2024\n",
      "Xiaomi announces Redmi 13R 5G with a familiar set of specs\n",
      "Meta AI is here: Know how to talk to the chatbot on WhatsApp, Instagram, and Facebook\n",
      "'Baldur's Gate 3', 'Alan Wake 2' win big at ad-heavy Game Awards 2023 • FRANCE 24 English\n",
      "Download OnePlus 12 wallpapers and live wallpapers here!\n",
      "Infinix Smart 8HD smartphone launched at just Rs 5,669\n",
      "Final Fantasy 7 Rebirth Fans Are Swooning Over Sexy Cid\n",
      "5 best perks to use in Warzone\n",
      "Generative AI Battle: Google's Gemini and OpenAI's GPT-4 features compared\n",
      "ROG Phone 8 officially teased\n",
      "1080° Snowboarding, Harvest Moon 64 and Jet Force Gemini join Nintendo Switch Online\n",
      "83-year-old man gets call from bank to update KYC online, later loses life savings\n",
      "Quordle 683 answer for December 8: Keep winning! Check Quordle hints, clues, solutions\n",
      "6 common smartphone mistakes that you must avoid\n",
      "5 ‘must try’ note-taking apps to boost productivity\n",
      "Fujifilm unveils campaign, aiming to connect India\n",
      "Gmail Receives A Major Upgrade As Google Intensifies Efforts Against Spam\n",
      "Upgrade your printing game with high quality printers on Amazon\n",
      "Best gifts under $25: Cheap presents that people on your list actually want.\n",
      "Fortnite launches Lego mode to rival Minecraft\n",
      "Boat launches its first LTE smartwatch with Jio eSIM support: All the details\n",
      "ChatGPT responds to complaints of being ‘lazy’, says ‘model behavior can be unpredictable’\n",
      "Best monitor for PS5 assure high-end gaming? Bring home one from top 10 options\n",
      "Best JBL Home Theater Systems To Elevate Your Entertainment!\n",
      "Gmail tips and tricks: 10 key hacks for better email handling\n",
      "WhatsApp could bring higher quality media for your status updates\n",
      "Explained: What is keyboard-based hacking on iPhones\n",
      "Character.AI, the quirky chatbot that lets you talk to AI replicas of celebrities; Know how to use it\n",
      "5 Smartphones To Buy Under Rs 25,000 in December 2023\n",
      "Best camera phones in 2023: From Apple to Redmi, here are our top 6 across all price range\n",
      "Urbn Nano Power Banks with up to 20,000 mAh capacity launched at Rs 1,699\n",
      "Garena Free Fire MAX Redeem Codes Today, December 8, 2023 Full List Of Latest Codes To Win Free Rewards Here\n",
      "TECNO Mobile’s SPARK Go 2024 debuts, available at retail stores and Amazon\n",
      "Apple збільшить виробництво iPhone в Індії до 50 мільйонів одиниць на рік – WSJ\n",
      "Flashback Friday\n",
      "10 best mobiles for gaming and streaming: From iQOO Neo 7 5G to iPhone 15 Pro, check them all out\n",
      "The Drive Report: 2023 BMW M340i\n",
      "Meta's Threads brings 'Tags' for organising posts by topics: Know details\n",
      "Suicide Squad Will Get An Offline Story Mode, Eventually\n",
      "「LibreOffice 7.6.4/7.5.9 Community」が公開 ～v7.5系はサポート終了、早急な移行を／フリーのオフィス統合環境の最新版\n",
      "Final Fantasy 16 DLC Echoes Of The Fallen Releases Today, Second DLC Coming Next Year\n",
      "Nothing Phone 3: News, leaks, rumored price, and release window\n",
      "Marvel's 'Blade,' Matthew McConaughey, Jordan Peele, 'Jurassic Park' all make splashy announcements at the Game Awards\n",
      "Monster Hunter Wilds revealed at The Game Awards 2023, coming in 2025\n",
      "7 dramatic bathroom design ideas for a chic black look\n",
      "Honkai Star Rail reveals Penacony at The Game Awards 2023: Expected release date and more\n",
      "Light No Fire is the next game from No Man's Sky studio Hello Games\n",
      "Stormgate\n",
      "Warhammer 40,000 Space Marine 2\n"
     ]
    }
   ],
   "source": [
    "for title in Tech_titles:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:47.364673Z",
     "iopub.status.busy": "2023-11-23T03:50:47.363944Z",
     "iopub.status.idle": "2023-11-23T03:50:47.373316Z",
     "shell.execute_reply": "2023-11-23T03:50:47.372548Z",
     "shell.execute_reply.started": "2023-11-23T03:50:47.364641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Tech_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:47.374642Z",
     "iopub.status.busy": "2023-11-23T03:50:47.374364Z",
     "iopub.status.idle": "2023-11-23T03:50:47.868750Z",
     "shell.execute_reply": "2023-11-23T03:50:47.867851Z",
     "shell.execute_reply.started": "2023-11-23T03:50:47.374619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Faithful Ride $7 Trillion Rally as Market Timing Backfires\n",
      "Why automakers are turning to hybrids in the middle of the industry's EV transition\n",
      "SmileDirectClub Rescue Deal Falls Apart, Company to Liquidate\n",
      "Warning from OpenAI leaders helped trigger Sam Altman's ouster\n",
      "DHL Express strike\n",
      "Starbucks Says It Wants Union Talks, Agreements in 2024\n",
      "Exxon Mobil is one of most oversold names, could be primed for bounce\n",
      "Paramount stock surges more than 14% as sale chatter mounts\n",
      "S&P 500 is little changed, on pace to snap 5-week win streak as comeback rally pauses: Live updates\n",
      "New McDonald's spinoff restaurant CosMc's officially opens in a Chicago suburb\n",
      "Bulk Deals: Softbank exits Zomato, GQG Partners buys Rs 1,671.5 cr shares in GMR Airports Infra\n",
      "Monitoring panel clears directors for Rel Naval board\n",
      "New laws taking effect in Minnesota on Jan. 1, 2024\n",
      "Elon Musk Throws Fresh Barbs at Disney's Bob Iger\n",
      "Kawasaki W175 Street Launched In India At Rs. 1.35 Lakh\n",
      "Paramount, RH, Carrier Global, Lululemon, First Solar, and More Market Movers\n",
      "Stocks gain, Treasury yields climb after US payrolls report\n",
      "Philanthropist MacKenzie Scott reveals the groups that got some of her $2.1 billion in gifts in 2023\n",
      "Tesla must respect collective bargaining rights, Norway's sovereign wealth fund says\n",
      "Huge global coffee supplier to liquidate in Chapter 11 bankruptcy\n",
      "FDA Approves First Gene Therapies to Treat Patients with Sickle Cell Disease\n",
      "Wealthy neighbors blast Jeff Bezos for 'not picking up trash on Cleanup Day': report\n",
      "Companies are spending millions to get AI into the hands of workers. Payback won't be quick\n",
      "For 2 Years in a Row, Man Has Won $10M at Same Store\n",
      "The self-checkout reversal is growing\n",
      "23andMe frantically changed its terms of service to prevent hacked customers from suing\n",
      "Inflation expectations plunge in closely watched University of Michigan survey\n",
      "AMD takes aim at Nvidia with new AI chips. Here's what might be next for the stock\n",
      "Google selects 20 AI-first startups for the eighth batch of its India accelerator programme\n",
      "MTA suspends Baltimore light rail services, what are the reasons for closure and for how long?\n",
      "No Better Market Than India Right Now: ICICI Prudential AMC S Naren\n",
      "Cantaloupe recall: Deaths linked to salmonella outbreak rises to 8\n",
      "Wipro announces top leadership change; chief growth officer quits\n",
      "Charlie Munger said there was no secret to his success: 'I avoided the standard ways of failing'\n",
      "Matrixport's $45K End of Year Target for Bitcoin Looks to Be Accurate\n",
      "Jeep-owner Stellantis announces mass layoffs, blames California\n",
      "Kia Sonet facelift 2024: Variant details leaked\n",
      "Weekly Funding Wrap: Large cheques, late-stage deals make a comeback; startups raise about $105 million\n",
      "Aprilia RS 457 launched at Rs 4.10 lakh: Ninja 400 rival with 47hp twin-cylinder engine\n",
      "JSW Steel Shares Hit 52-Week High as Arm Plans to Raise Long-Term Funds\n",
      "A Bull Market Is Coming: 1 Magnificent Artificial Intelligence (AI) Growth Stock to Buy Hand Over Fist Before 2024 and Hold Forever\n",
      "Praj Industries Shares Plummet 14% After Ban on Ethanol Production\n",
      "India’s largest consumer care company shows negative momentum. What gives\n",
      "Microsoft's links with OpenAI to be examined by competition watchdog\n",
      "[Removed]\n",
      "Japan's Q3 GDP falls faster than first estimates as consumption sags\n",
      "India's forex reserves touch four-month high at $604 billion: RBI\n",
      "Zerodha's Kamath brothers take home Rs 72 crore each in remuneration in FY23\n",
      "$19 Billion in a Week: AbbVie Makes Two Big Bets\n",
      "Piramal Pharma to invest ₹1,000 cr for expansion: Nandini Piramal\n",
      "Savings Of Up To Rs 59,000 On Maruti Arena Cars This December\n",
      "Carrier Announces Agreement to Sell Global Access Solutions Business to Honeywell for $4.95 Billion\n",
      "Here’s what to know as the Seminole Tribe launches sports betting, table games in Tampa\n",
      "最新機種が続々！洗剤不要の洗濯機やふっくら仕上げの大容量乾燥機など（2023年12月8日）#WBS\n",
      "Mullen Provides Securities Litigation Update\n",
      "The biggest study of ‘greedflation’ yet looked at 1,300 corporations to find many of them were lying to you about inflation\n",
      "Bank Nifty hits record high of 47,303, clocks biggest weekly gain since July 2022\n",
      "Has Microsoft taken over control of OpenAI? Brad Smith issues clarification\n",
      "Supreme Court: Supreme Court dismisses Chanda Kochhar's plea for retirement benefits from ICICI bank\n",
      "SIPs hit a new high in November, exceeding ₹17,000 crore\n",
      "Tata Punch EV launch on December 21\n",
      "Woman claims Airtel imposed ₹1 lakh roaming charges during her trip to Bihar\n",
      "MC Interview: Hindalco has ability to invest in commodity downcycle; $4.4 billion capex on track: MD\n",
      "What does RBI’s MPC meet outcome spell for banking and housing loan sectors?\n",
      "The great awakening: HDFC Bank shows cup and handle pattern breakout after 2 years of consolidation\n",
      "Washington Post strikers say 'we deserve better' as they walk off job in historic protest\n",
      "2024 Skoda Kushaq & Slavia Elegance Edition\n",
      "Pharma stock jumps up to 20% after merger with Dhanuka Laboratories; Check the latest targets\n",
      "Gold price on December 8: Rates in main Indian cities\n",
      "Indias Foreign Inflows To Grow But Not At The Cost Of China Yet, Says Samir Arora\n",
      "India’s top VCs face fresh obstacles as startup investment plummets\n",
      "RBI monetary policy: Governor Das says central bank working on establishing cloud facility for financials\n",
      "AMD Stock (NASDAQ:AMD): Will AI-Fueled Rally Lose Steam?\n",
      "Soaring Adani Shares Push LIC To Newer Highs --Check What Experts Say\n",
      "Heavy buying after FIIs increasing stake: Back-to-back upper circuits and 52-week highs in this multibagger micro-cap stock; scrip up by 30000 per cent!\n",
      "Apple's strategic pivot: A quarter of world's iPhones to be made in India\n",
      "Block Deal: Midcap stock jumps 14% after 76 Cr equity shares exchanged hands\n",
      "EV stock jumps after it receives order worth ₹ 62.80 Cr for supply of 40 electric buses\n",
      "Tata Group set to build one of the largest iPhone assembly plant in India: Location, jobs to be created a\n",
      "Sensex hits all-time high; Nifty scales 21,000 mark post RBI policy decision\n",
      "Paytm Shares Rebound After Worst Fall Since Listing\n",
      "IREDA soars 14% on heavy volumes; stock zooms 129% against issue price\n",
      "Marinetrans India share price hits 5% lower circuit after listing at 15.4% premium on NSE SME exchange\n",
      "DOMS IPO: GMP jumps as issue opens next week. Date, price, other details of upcoming IPO\n",
      "Public sector bankers to get 17 per cent wage hike\n",
      "Gautam Adani shares plan for Adani Ports, ‘carbon neutral by 2025, net zero by 2040’\n",
      "NDTV Profit Is Back, Business Channel Relaunches In New Avatar\n",
      "OMB focused on automation, federal employee satisfaction as keys to better public-facing services\n",
      "Seattle cancer patients face blackmail threats after recent Fred Hutch data breach\n",
      "Louisville Teamsters warn of strike against UPS citing unfair labor practices\n",
      "US Judge Bans Changpeng ‘CZ’ Zhao from Leaving the Country\n",
      "Oil prices jump after U.S. jobs report By Investing.com\n",
      "Cathay Pacific chooses Airbus over Boeing for freighter order\n",
      "Stocks to Watch: Zomato, Maruti Suzuki, SpiceJet, IDFC First Bank\n",
      "Eye on elections: PSU bank stocks may continue to race ahead as BJP prospects instill confidence\n",
      "Off-Duty Pilot, Joseph Emerson, Released\n",
      "Nifty 50, Sensex today: What to expect from stock market indices in trade on December 8\n",
      "X begins rolling out Grok, its ‘rebellious’ chatbot, to subscribers\n",
      "House Republicans have once again voted to poison you and cost you trillions\n",
      "Stock Market Today: All You Need To Know Going Into Trade On Dec. 8\n"
     ]
    }
   ],
   "source": [
    "# set the request parameters\n",
    "params = {\n",
    "    'category': 'business',\n",
    "    'language': 'en',\n",
    "    'pageSize': 100,\n",
    "    'apiKey': 'e30743332dd1426eb170927023ba09d7'\n",
    "}\n",
    "\n",
    "# send the request and get the response\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "# get the 'articles' list from the response JSON data\n",
    "articles = response.json()['articles']\n",
    "\n",
    "# extract the titles from the articles aslo splitting the source from titles\n",
    "Business_titles = [article['title'].split(' - ')[0].split(' | ')[0] for article in articles]\n",
    "\n",
    "# print the titles\n",
    "for title in Business_titles:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:47.869947Z",
     "iopub.status.busy": "2023-11-23T03:50:47.869688Z",
     "iopub.status.idle": "2023-11-23T03:50:47.875618Z",
     "shell.execute_reply": "2023-11-23T03:50:47.874789Z",
     "shell.execute_reply.started": "2023-11-23T03:50:47.869910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Business_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:47.877239Z",
     "iopub.status.busy": "2023-11-23T03:50:47.876982Z",
     "iopub.status.idle": "2023-11-23T03:50:47.885110Z",
     "shell.execute_reply": "2023-11-23T03:50:47.884282Z",
     "shell.execute_reply.started": "2023-11-23T03:50:47.877206Z"
    }
   },
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for title in Tech_titles:\n",
    "    data_list.append({'sentence': str(title), 'label': 0}) \n",
    "\n",
    "for title in Business_titles:\n",
    "    data_list.append({'sentence': str(title), 'label': 1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:47.886225Z",
     "iopub.status.busy": "2023-11-23T03:50:47.885964Z",
     "iopub.status.idle": "2023-11-23T03:50:47.908001Z",
     "shell.execute_reply": "2023-11-23T03:50:47.907132Z",
     "shell.execute_reply.started": "2023-11-23T03:50:47.886202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              sentence  label\n",
      "0    Beeper Mini's iMessage integration is on the f...      0\n",
      "1     PUBG Mobile guide to avoid dying (December 2023)      0\n",
      "2    Apple's iPhone and Watch Product Design Chief ...      0\n",
      "3                                        Den of Wolves      0\n",
      "4     Minecraft – Jurassic World DLC – Nintendo Switch      0\n",
      "..                                                 ...    ...\n",
      "195           Off-Duty Pilot, Joseph Emerson, Released      1\n",
      "196  Nifty 50, Sensex today: What to expect from st...      1\n",
      "197  X begins rolling out Grok, its ‘rebellious’ ch...      1\n",
      "198  House Republicans have once again voted to poi...      1\n",
      "199  Stock Market Today: All You Need To Know Going...      1\n",
      "\n",
      "[200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(data_list)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:47.909558Z",
     "iopub.status.busy": "2023-11-23T03:50:47.909236Z",
     "iopub.status.idle": "2023-11-23T03:50:47.924373Z",
     "shell.execute_reply": "2023-11-23T03:50:47.923449Z",
     "shell.execute_reply.started": "2023-11-23T03:50:47.909525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>The biggest study of ‘greedflation’ yet looked...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Apple's strategic pivot: A quarter of world's ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>The self-checkout reversal is growing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Google faces controversy over edited Gemini AI...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>For some reason Yamaha is launching a 5-disk C...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  label\n",
       "155  The biggest study of ‘greedflation’ yet looked...      1\n",
       "175  Apple's strategic pivot: A quarter of world's ...      1\n",
       "124              The self-checkout reversal is growing      1\n",
       "11   Google faces controversy over edited Gemini AI...      0\n",
       "23   For some reason Yamaha is launching a 5-disk C...      0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = shuffle(data, random_state=987654321)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:47.925760Z",
     "iopub.status.busy": "2023-11-23T03:50:47.925462Z",
     "iopub.status.idle": "2023-11-23T03:50:47.934701Z",
     "shell.execute_reply": "2023-11-23T03:50:47.933960Z",
     "shell.execute_reply.started": "2023-11-23T03:50:47.925725Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = data.drop('label', axis=1)\n",
    "y_train = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:47.936020Z",
     "iopub.status.busy": "2023-11-23T03:50:47.935715Z",
     "iopub.status.idle": "2023-11-23T03:50:47.946405Z",
     "shell.execute_reply": "2023-11-23T03:50:47.945511Z",
     "shell.execute_reply.started": "2023-11-23T03:50:47.935995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:47.947615Z",
     "iopub.status.busy": "2023-11-23T03:50:47.947390Z",
     "iopub.status.idle": "2023-11-23T03:50:47.956878Z",
     "shell.execute_reply": "2023-11-23T03:50:47.956126Z",
     "shell.execute_reply.started": "2023-11-23T03:50:47.947594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training (at least 160 examples) and test (at least 40 examples) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:47.958197Z",
     "iopub.status.busy": "2023-11-23T03:50:47.957907Z",
     "iopub.status.idle": "2023-11-23T03:50:47.968229Z",
     "shell.execute_reply": "2023-11-23T03:50:47.967441Z",
     "shell.execute_reply.started": "2023-11-23T03:50:47.958174Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=40, random_state=987654321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:47.969558Z",
     "iopub.status.busy": "2023-11-23T03:50:47.969250Z",
     "iopub.status.idle": "2023-11-23T03:50:47.977936Z",
     "shell.execute_reply": "2023-11-23T03:50:47.977057Z",
     "shell.execute_reply.started": "2023-11-23T03:50:47.969521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "160\n",
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune a pretrained language model capable of generating text (e.g., GPT) that you can take from the Hugging Face Transformers library with the dataset your created (this tutorial could be very helpful: https://huggingface.co/docs/transformers/training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:47.979165Z",
     "iopub.status.busy": "2023-11-23T03:50:47.978872Z",
     "iopub.status.idle": "2023-11-23T03:50:47.999440Z",
     "shell.execute_reply": "2023-11-23T03:50:47.998700Z",
     "shell.execute_reply.started": "2023-11-23T03:50:47.979142Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(987654321)\n",
    "np.random.seed(987654321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## !pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Albert-base-v2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:48.001277Z",
     "iopub.status.busy": "2023-11-23T03:50:48.000469Z",
     "iopub.status.idle": "2023-11-23T03:50:57.411232Z",
     "shell.execute_reply": "2023-11-23T03:50:57.410348Z",
     "shell.execute_reply.started": "2023-11-23T03:50:48.001245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4794cfc255e48e2916d85448630584f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFAlbertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFAlbertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# initializing a tokenizer and a pre-trained model for sequence classification using the ALBERT-base-v2 architecture\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"albert-base-v2\")\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"albert-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:57.412583Z",
     "iopub.status.busy": "2023-11-23T03:50:57.412303Z",
     "iopub.status.idle": "2023-11-23T03:50:57.434981Z",
     "shell.execute_reply": "2023-11-23T03:50:57.434313Z",
     "shell.execute_reply.started": "2023-11-23T03:50:57.412557Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = dict(tokenizer([str(i) for i in X_train['sentence']], return_tensors='np', padding=True))\n",
    "X_test = dict(tokenizer([str(i) for i in X_test['sentence']], return_tensors='np', padding=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:50:57.439620Z",
     "iopub.status.busy": "2023-11-23T03:50:57.439350Z",
     "iopub.status.idle": "2023-11-23T03:51:20.171299Z",
     "shell.execute_reply": "2023-11-23T03:51:20.170320Z",
     "shell.execute_reply.started": "2023-11-23T03:50:57.439596Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "2/2 [==============================] - 13s 5s/step - loss: 0.6960\n",
      "Epoch 2/4\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.6202\n",
      "Epoch 3/4\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.5775\n",
      "Epoch 4/4\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.5064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17d618c50>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(1e-5))\n",
    "model.fit(X_train, y_train,epochs=4, batch_size=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:51:20.172653Z",
     "iopub.status.busy": "2023-11-23T03:51:20.172392Z",
     "iopub.status.idle": "2023-11-23T03:51:23.675996Z",
     "shell.execute_reply": "2023-11-23T03:51:23.675193Z",
     "shell.execute_reply.started": "2023-11-23T03:51:20.172629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 172ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)[\"logits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:51:23.677722Z",
     "iopub.status.busy": "2023-11-23T03:51:23.677368Z",
     "iopub.status.idle": "2023-11-23T03:51:23.682613Z",
     "shell.execute_reply": "2023-11-23T03:51:23.681690Z",
     "shell.execute_reply.started": "2023-11-23T03:51:23.677687Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:51:23.684294Z",
     "iopub.status.busy": "2023-11-23T03:51:23.684006Z",
     "iopub.status.idle": "2023-11-23T03:51:24.226368Z",
     "shell.execute_reply": "2023-11-23T03:51:24.225428Z",
     "shell.execute_reply.started": "2023-11-23T03:51:23.684269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f473c4b9c11545af983dd96feb9b1df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.775}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = evaluate.load('accuracy')\n",
    "metric.compute(predictions=y_pred, references=np.array(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss what could be done to improve accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that when we compile the model with 4 epochs, the training loss is reduced at each step. When we calculate the accuracy, we get 77.5% accuracy. If we increase the epochs, we can potentially obtain better accuracy, but there is also a risk of overfitting the model. Hence, we will test the model with epoch = 20 to further evaluate its performance. However, we can add regularization techniques like dropout to prevent overfitting. We can also experiment with different batch sizes. A smaller batch size may allow the model to generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:51:24.228127Z",
     "iopub.status.busy": "2023-11-23T03:51:24.227546Z",
     "iopub.status.idle": "2023-11-23T03:51:24.269725Z",
     "shell.execute_reply": "2023-11-23T03:51:24.268743Z",
     "shell.execute_reply.started": "2023-11-23T03:51:24.228091Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(987654321)\n",
    "np.random.seed(987654321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:51:24.271593Z",
     "iopub.status.busy": "2023-11-23T03:51:24.271293Z",
     "iopub.status.idle": "2023-11-23T03:51:49.059039Z",
     "shell.execute_reply": "2023-11-23T03:51:49.058214Z",
     "shell.execute_reply.started": "2023-11-23T03:51:24.271567Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 12s 5s/step - loss: 0.4674\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.4080\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.3636\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.3184\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.2799\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.2497\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.2130\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.1895\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.1616\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.1371\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.1156\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.0997\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.0854\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.0700\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.0594\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.0505\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.0435\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.0377\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.0307\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.0259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28ade4610>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(1e-5))\n",
    "model.fit(X_train, y_train,epochs=20, batch_size=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:51:49.060319Z",
     "iopub.status.busy": "2023-11-23T03:51:49.060046Z",
     "iopub.status.idle": "2023-11-23T03:51:52.079101Z",
     "shell.execute_reply": "2023-11-23T03:51:52.078207Z",
     "shell.execute_reply.started": "2023-11-23T03:51:49.060295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 181ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)[\"logits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:51:52.082023Z",
     "iopub.status.busy": "2023-11-23T03:51:52.081701Z",
     "iopub.status.idle": "2023-11-23T03:51:52.086318Z",
     "shell.execute_reply": "2023-11-23T03:51:52.085465Z",
     "shell.execute_reply.started": "2023-11-23T03:51:52.081995Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:51:52.087734Z",
     "iopub.status.busy": "2023-11-23T03:51:52.087463Z",
     "iopub.status.idle": "2023-11-23T03:51:52.480372Z",
     "shell.execute_reply": "2023-11-23T03:51:52.479451Z",
     "shell.execute_reply.started": "2023-11-23T03:51:52.087709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.85}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = evaluate.load('accuracy')\n",
    "metric.compute(predictions=y_pred, references=np.array(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the model with 20 epochs, we observed a decrease in the training loss at each step. The accuracy obtained was 85%, which is higher than the accuracy obtained with 4 epochs. However, we could have achieved even higher accuracy if we had used a larger model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying different models to gain a better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:51:52.481709Z",
     "iopub.status.busy": "2023-11-23T03:51:52.481433Z",
     "iopub.status.idle": "2023-11-23T03:51:52.519491Z",
     "shell.execute_reply": "2023-11-23T03:51:52.518405Z",
     "shell.execute_reply.started": "2023-11-23T03:51:52.481685Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(987654321)\n",
    "np.random.seed(987654321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using GPT-J**\n",
    "> Computationally expensive since the model requires around 24.2 GB of memory space to download.\n",
    "\n",
    "> Too big to be used on regular hardware: wouldn't fit in RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:52:28.131257Z",
     "iopub.status.busy": "2023-11-23T03:52:28.130278Z",
     "iopub.status.idle": "2023-11-23T03:52:43.385289Z",
     "shell.execute_reply": "2023-11-23T03:52:43.383483Z",
     "shell.execute_reply.started": "2023-11-23T03:52:28.131225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616881affb5744559f07f5815e67b8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b93d182a1543cea3bde8c7840d5146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd464c2540745db950990516cee0735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f7f20876e7043ed8f742a7a5d2196da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.37M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e326d3b46574df686f263c62b025299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/4.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff360cbbda934e25ad9c2a6d1db581a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d48acf60c14d52ae53ac4a151aadb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/930 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0b71024d7f4e36b679caa9ab3b9f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/24.2G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEleutherAI/gpt-j-6B\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m TFAutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEleutherAI/gpt-j-6B\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(\u001b[38;5;241m1e-5\u001b[39m))\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    567\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    568\u001b[0m     )\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:2792\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m SAFE_WEIGHTS_NAME:\n\u001b[1;32m   2789\u001b[0m     \u001b[38;5;66;03m# Did not find the safetensors file, let's fallback to TF.\u001b[39;00m\n\u001b[1;32m   2790\u001b[0m     \u001b[38;5;66;03m# No support for sharded safetensors yet, so we'll raise an error if that's all we find.\u001b[39;00m\n\u001b[1;32m   2791\u001b[0m     filename \u001b[38;5;241m=\u001b[39m TF2_WEIGHTS_NAME\n\u001b[0;32m-> 2792\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m   2793\u001b[0m         pretrained_model_name_or_path, TF2_WEIGHTS_NAME, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcached_file_kwargs\n\u001b[1;32m   2794\u001b[0m     )\n\u001b[1;32m   2795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m TF2_WEIGHTS_NAME:\n\u001b[1;32m   2796\u001b[0m     \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n\u001b[1;32m   2797\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m   2798\u001b[0m         pretrained_model_name_or_path, TF2_WEIGHTS_INDEX_NAME, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcached_file_kwargs\n\u001b[1;32m   2799\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/hub.py:430\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    431\u001b[0m         path_or_repo_id,\n\u001b[1;32m    432\u001b[0m         filename,\n\u001b[1;32m    433\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[1;32m    434\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    435\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    436\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    437\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    438\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    439\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    440\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    441\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    442\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    443\u001b[0m     )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to request access at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and pass a token having permission to this repo either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1461\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1458\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1459\u001b[0m             _check_disk_space(expected_size, local_dir)\n\u001b[0;32m-> 1461\u001b[0m     http_get(\n\u001b[1;32m   1462\u001b[0m         url_to_download,\n\u001b[1;32m   1463\u001b[0m         temp_file,\n\u001b[1;32m   1464\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1465\u001b[0m         resume_size\u001b[38;5;241m=\u001b[39mresume_size,\n\u001b[1;32m   1466\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1467\u001b[0m         expected_size\u001b[38;5;241m=\u001b[39mexpected_size,\n\u001b[1;32m   1468\u001b[0m     )\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1471\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStoring \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblob_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:541\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, _nb_retries)\u001b[0m\n\u001b[1;32m    539\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 541\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39mDOWNLOAD_CHUNK_SIZE):\n\u001b[1;32m    542\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    543\u001b[0m             progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp):\n\u001b[0;32m--> 628\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(amt\u001b[38;5;241m=\u001b[39mamt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m    631\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    564\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 567\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp_read(amt) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         flush_decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buffer\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1276\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1277\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "\n",
    "model.compile(optimizer=Adam(1e-5))\n",
    "model.fit(X_train, y_train,epochs=20, batch_size=80)\n",
    "\n",
    "preds = model.predict(X_test)[\"logits\"]\n",
    "\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "\n",
    "metric = evaluate.load('accuracy')\n",
    "metric.compute(predictions=y_pred, references=np.array(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using GPT-Sw3**\n",
    "> Not released publicly: requires token access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T03:55:42.440518Z",
     "iopub.status.busy": "2023-11-23T03:55:42.439550Z",
     "iopub.status.idle": "2023-11-23T03:55:42.994329Z",
     "shell.execute_reply": "2023-11-23T03:55:42.992885Z",
     "shell.execute_reply.started": "2023-11-23T03:55:42.440483Z"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "AI-Sweden/gpt-sw3-356m is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py:270\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/AI-Sweden/gpt-sw3-356m/resolve/main/tokenizer_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/hub.py:430\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    431\u001b[0m         path_or_repo_id,\n\u001b[1;32m    432\u001b[0m         filename,\n\u001b[1;32m    433\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[1;32m    434\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    435\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    436\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    437\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    438\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    439\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    440\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    441\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    442\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    443\u001b[0m     )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1374\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;66;03m# Repo not found => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1374\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1247\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1247\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m get_hf_file_metadata(\n\u001b[1;32m   1248\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   1249\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   1250\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1251\u001b[0m         timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[1;32m   1252\u001b[0m     )\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;66;03m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1624\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1624\u001b[0m r \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[1;32m   1625\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1626\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   1627\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1628\u001b[0m     allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1629\u001b[0m     follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1630\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1631\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m   1632\u001b[0m )\n\u001b[1;32m   1633\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:402\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 402\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[1;32m    403\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    404\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    405\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    407\u001b[0m     )\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:426\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    425\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 426\u001b[0m hf_raise_for_status(response)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py:320\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    312\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    319\u001b[0m     )\n\u001b[0;32m--> 320\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-6574ff10-544f0ad83a0e11b9611ac46e;260f302e-4a40-4b20-8303-ff2163bbc870)\n\nRepository Not Found for url: https://huggingface.co/AI-Sweden/gpt-sw3-356m/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI-Sweden/gpt-sw3-356m\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m TFAutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI-Sweden/gpt-sw3-356m\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(\u001b[38;5;241m1e-5\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:718\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m get_tokenizer_config(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[1;32m    720\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:550\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m     token \u001b[38;5;241m=\u001b[39m use_auth_token\n\u001b[1;32m    549\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 550\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m    551\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m    552\u001b[0m     TOKENIZER_CONFIG_FILE,\n\u001b[1;32m    553\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    554\u001b[0m     force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    555\u001b[0m     resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    556\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    557\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    558\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    559\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    560\u001b[0m     subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[1;32m    561\u001b[0m     _raise_exceptions_for_missing_entries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    562\u001b[0m     _raise_exceptions_for_connection_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    563\u001b[0m     _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[1;32m    564\u001b[0m )\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    566\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/hub.py:451\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to request access at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and pass a token having permission to this repo either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    452\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    456\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    462\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: AI-Sweden/gpt-sw3-356m is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"AI-Sweden/gpt-sw3-356m\")\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"AI-Sweden/gpt-sw3-356m\")\n",
    "\n",
    "model.compile(optimizer=Adam(1e-5))\n",
    "model.fit(X_train, y_train,epochs=20, batch_size=80)\n",
    "\n",
    "preds = model.predict(X_test)[\"logits\"]\n",
    "\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "\n",
    "metric = evaluate.load('accuracy')\n",
    "metric.compute(predictions=y_pred, references=np.array(y_test))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
